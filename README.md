#  An谩lisis de Tr谩fico con Visi贸n Artificial y OpenCV
**Autores:** Alejandro Delgado y Tom谩s Santana  
**Asignatura:** Fundamentos de los Sistemas Inteligentes *(Pr谩ctica 1)*  
**Universidad de Las Palmas de Gran Canaria - Curso 25/26**  
**Versi贸n:** v1.0  

---

## 1. Introducci贸n y Objetivos
El presente proyecto tiene como objetivo el desarrollo de un sistema de visi贸n artificial capaz de detectar, contar, clasificar y estimar la velocidad de veh铆culos en v铆as de tr谩fico. La implementaci贸n se ha realizado en Python utilizando la librer铆a **OpenCV** para el procesamiento de imagen y **Tkinter** para la interfaz de usuario, siguiendo una metodolog铆a de desarrollo incremental que culmin贸 en una refactorizaci贸n modular.

## 2. Metodolog铆a y Evoluci贸n del Desarrollo

El desarrollo del sistema ha seguido un enfoque iterativo dividido en cuatro fases claramente diferenciadas, que permitieron evolucionar desde pruebas de concepto b谩sicas hasta una aplicaci贸n robusta y estructurada.

### Fase 1: Prototipado Inicial (`funcionesV1.py`)
En la etapa inicial, se desarrollaron scripts procedimentales para validar las t茅cnicas b谩sicas de visi贸n por computador:
* **Extracci贸n de Fondo:** Implementaci贸n del algoritmo de promedio temporal (`obtener_fondo`) para generar un modelo est谩tico del fondo vac铆o, eliminando los veh铆culos en movimiento de la escena base.
* **Detecci贸n B谩sica:** Uso de la diferencia absoluta (`cv2.absdiff`) y umbralizaci贸n binaria para detectar movimiento y validar la obtenci贸n de Regiones de Inter茅s (ROIs).
* **Enfoque Inicial (L铆nea Virtual):** Se implement贸 inicialmente un m茅todo simple de conteo basado en l铆neas virtuales. Esta t茅cnica registraba un veh铆culo cada vez que el centroide de la detecci贸n cruzaba una coordenada de p铆xel predefinida. Esta soluci贸n fue r谩pida para validar la detecci贸n de movimiento, pero demostr贸 ser no escalable para el resto de requisitos del proyecto (estimaci贸n de velocidad, clasificaci贸n y manejo de oclusiones). Por sugerencia del profesorado, se determin贸 que el enfoque de l铆nea deb铆a ser reemplazado por un sistema basado en persistencia de identidad (tracking).
  
* *Limitaci贸n:* Estas funciones sirvieron como prueba de concepto pero carec铆an de persistencia temporal (*tracking*), lo que provocaba conteos err贸neos ante parpadeos o detenciones.

### Fase 2: Arquitectura Orientada a Objetos
Para resolver los problemas de p茅rdida de identidad y dotar al sistema de "memoria", se migr贸 el n煤cleo l贸gico hacia un paradigma de Orientaci贸n a Objetos:
* **Modelo `Vehiculo` (`vehiculos.py`):** Se encapsul贸 el estado de cada coche en un objeto. La mejora cr铆tica fue la integraci贸n del **Filtro de Kalman** (`cv2.KalmanFilter`). Este filtro permite predecir la posici贸n futura del veh铆culo y suavizar su trayectoria, siendo esencial para obtener una estimaci贸n estable de la velocidad y evitar saltos en la detecci贸n.
* **Controlador `GestorVehiculos` (`gestor_vehiculos.py`):** Se desarroll贸 un gestor de identidades capaz de asociar las detecciones de cada *frame* con los veh铆culos existentes, minimizando la distancia euclidiana. Adem谩s, maneja oclusiones temporales mediante un sistema de "paciencia" (`max_frames_perdido`), permitiendo recuperar la identidad de un coche tras pasar tras un obst谩culo.

### Fase 3: L贸gica Avanzada (`funcionesV2.py`)
Sobre la base de objetos, se desarrollaron algoritmos complejos para cumplir los requisitos funcionales de la pr谩ctica:
* **Correcci贸n de Fragmentaci贸n:** Se detect贸 que veh铆culos grandes (camiones) se divid铆an en m煤ltiples detecciones. Se implement贸 el algoritmo `fusionar_detecciones_cercanas` para agrupar detecciones pr贸ximas en una sola entidad.
* **Clasificaci贸n y F铆sica:** Implementaci贸n de l贸gica para diferenciar entre **Motos, Coches y Camiones** analizando el 谩rea del contorno y su relaci贸n de aspecto (*aspect ratio*). C谩lculo de la velocidad vectorial y determinaci贸n del sentido de la marcha (Subiendo/Bajando, Izquierda/Derecha).
* **Gesti贸n de Atascos:** Integraci贸n del sustractor de fondo din谩mico **MOG2**, permitiendo al sistema adaptarse a cambios de luz y gestionar veh铆culos que se detienen (incorpor谩ndolos al fondo temporalmente).
* **Correcci贸n de Velocidad por Perspectiva:** Se incluy贸 un par谩metro de `factor_perspectiva_max` y la l贸gica asociada, que aplica una **interpolaci贸n lineal** a la velocidad para corregir el sesgo de la c谩mara. Esto asegura que los veh铆culos lejanos (que visualmente se mueven menos p铆xeles) reporten una velocidad coherente con los veh铆culos cercanos.

### Fase 4: Refactorizaci贸n e Integraci贸n Final (`functions.py`)
En la etapa final del desarrollo, se realiz贸 una limpieza y unificaci贸n del c贸digo (**Refactoring**) para mejorar la calidad del software.
* **Unificaci贸n de M贸dulos:** Se fusionaron las primitivas robustas de la Fase 1 (lectura y preprocesamiento) con la l贸gica avanzada de la Fase 3 en un 煤nico m贸dulo consolidado llamado **`functions.py`**.
* **Beneficio:** Esta reestructuraci贸n elimin贸 redundancias, centraliz贸 toda la l贸gica de visi贸n computacional en un solo fichero y simplific贸 las dependencias del proyecto.

---

### Gesti贸n del Flujo de Trabajo y Control de Versiones
Para garantizar un desarrollo ordenado y colaborativo, se implement贸 una estrategia de control de versiones basada en GitFlow simplificado. El flujo de trabajo se estructur贸 de la siguiente manera:

* **Rama de Desarrollo (`dev`):** Actu贸 como el eje central de integraci贸n. Todo el c贸digo estable se unificaba en esta rama.
* **Ramas de Funcionalidad (`feat/...`):** Cada nueva caracter铆stica o m贸dulo (ej. `feat/filtro-kalman`, `feat/interfaz-tkinter`) se desarroll贸 en una rama aislada creada a partir de `dev`.
* **Pull Requests (PR):** La fusi贸n de las ramas `feat` hacia `dev` se realiz贸 exclusivamente mediante *Pull Requests*. Esto permiti贸 revisar el c贸digo por ambos miembros antes de integrarlo, evitando conflictos y asegurando que la rama de desarrollo se mantuviera funcional en todo momento.

## 3. Aporte Personal: Interfaz Gr谩fica de Usuario (GUI)

**Decisi贸n de arquitectura (Rendimiento):** Inicialmente, se prototip贸 una GUI con Streamlit. Sin embargo, debido a la latencia inherente de la compresi贸n y transmisi贸n de v铆deo en tiempo real en entornos web, se tom贸 la decisi贸n de migrar la interfaz a la tecnolog铆a nativa de Tkinter. Esto elimin贸 el lag y garantiz贸 la reproducci贸n fluida del v铆deo a tiempo real, algo cr铆tico para una herramienta de visi贸n por computador.
Como valor a帽adido significativo al proyecto, se ha desarrollado una aplicaci贸n de escritorio completa utilizando la librer铆a **Tkinter**. El objetivo de este aporte es transformar el script de detecci贸n en una herramienta de software usable por un usuario final sin conocimientos de programaci贸n.

Las caracter铆sticas principales de la interfaz (`app-tkinter.py`) incluyen:

* **Carga de V铆deos Intuitiva:** Permite al usuario seleccionar archivos de v铆deo locales mediante un explorador de archivos nativo.
* **Panel de Configuraci贸n Din谩mica:** Se ha dise帽ado un panel de control lateral que permite ajustar en tiempo real los par谩metros cr铆ticos del algoritmo sin reiniciar la aplicaci贸n:
    * Ajuste de sensibilidad de detecci贸n y 谩reas m铆nimas/m谩ximas para filtrar ruido.
    * Selecci贸n del m茅todo de fondo (Est谩tico vs Din谩mico MOG2).
    * Configuraci贸n de la orientaci贸n de la v铆a (Vertical/Horizontal).
* **Visualizaci贸n Parametrizable:** Controles (*Checkboxes*) para activar o desactivar capas de informaci贸n sobre el v铆deo (mostrar/ocultar IDs, vectores de velocidad, contadores globales, cajas delimitadoras, etc.).
* **Persistencia de Par谩metros (Presets):** Se implement贸 la funcionalidad para Guardar y **Cargar configuraciones en ficheros JSON**. Esto permite al usuario guardar un conjunto 贸ptimo de par谩metros (sensibilidad, 谩reas, ROI, etc.) para un v铆deo espec铆fico y reutilizarlo con un solo clic, sin tener que reajustar los sliders manualmente.

Esta interfaz act煤a como orquestador, conectando la entrada del usuario con la l贸gica del m贸dulo `functions.py` y el `GestorVehiculos`, haciendo del sistema una soluci贸n flexible y adaptable a diferentes escenarios de tr谩fico.

## 4. Conclusiones
El sistema desarrollado culmina en una herramienta funcional y altamente configurable para el an谩lisis de tr谩fico. La combinaci贸n de la arquitectura Orientada a Objetos con el Filtro de Kalman ha resuelto con 茅xito los problemas de p茅rdida de identidad y ofrece un tracking robusto, permitiendo una clasificaci贸n y estimaci贸n de velocidad coherente (gracias a la correcci贸n de perspectiva).

No obstante, es fundamental reconocer las limitaciones inherentes a los m茅todos cl谩sicos de Visi贸n por Computador (OpenCV). Al depender 煤nicamente de la resta de fondo (`absdiff`/`MOG2`) y el an谩lisis de contornos, el sistema puede enfrentar dificultades significativas bajo ciertas condiciones:

* **Condiciones Ambientales:** Baja luz, lluvia, niebla o reflejos solares pueden degradar seriamente la calidad de la detecci贸n.
* **Oclusiones y Congesti贸n Extrema:** En situaciones de tr谩fico muy denso, la superposici贸n de objetos (`blobs`) puede desafiar incluso al Filtro de Kalman, afectando la estabilidad del tracking.

Si bien la soluci贸n actual cumple con todos los objetivos y demuestra una implementaci贸n s贸lida de los principios de Sistemas Inteligentes, para alcanzar una precisi贸n "cercana a la perfecci贸n" en un entorno real y diverso, el paso siguiente en la evoluci贸n del proyecto ser铆a migrar la fase de detecci贸n a modelos de Deep Learning (como YOLO o SSD).

<br>

<p align="center">
  <img width="50%" alt="image" src="https://github.com/user-attachments/assets/b4c47d04-6ee6-4bc7-af93-7d05c473e2d6" />
</p>
